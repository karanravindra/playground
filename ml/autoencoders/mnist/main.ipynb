{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "from nn_zoo.datamodules import MNISTDataModule\n",
    "from nn_zoo.models.components import ResidualStack, DepthwiseSeparableConv2d\n",
    "from nn_zoo.trainers import AutoEncoderTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MNISTDataModule(\n",
    "        data_dir=\"data\",\n",
    "        dataset_params={\n",
    "            \"download\": True,\n",
    "            \"transform\": torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize((32, 32)),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                ]\n",
    "            ),\n",
    "        },\n",
    "        loader_params={\n",
    "            \"batch_size\": 128,\n",
    "            \"num_workers\": 2,\n",
    "            \"persistent_workers\": True,\n",
    "            \"pin_memory\": True,\n",
    "        },\n",
    "    )\n",
    "\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "train_loader = dm.train_dataloader()\n",
    "test_loader = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifer(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Identity()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Classifer(nn.Module):\n",
    "    def __init__(self, width: int, depth: int):\n",
    "        super(Classifer, self).__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(8, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    @classmethod\n",
    "    def loss(cls, y_hat, y):\n",
    "        return F.cross_entropy(y_hat, y)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def lpips_loss(self, x, y):\n",
    "        return F.mse_loss(x, y)\n",
    "\n",
    "classifer = Classifer(0, 0)\n",
    "\n",
    "state_dict = torch.load(\"/Users/karan/projects/playground/mnist-classifier/n8a9otdh/checkpoints/epoch=9-step=9380.ckpt\")[\"state_dict\"]\n",
    "\n",
    "for name, param in classifer.named_parameters():\n",
    "    if name in state_dict:\n",
    "        param.data = state_dict[\"model.\" + name]\n",
    "\n",
    "classifer.classifier = nn.Identity()\n",
    "classifer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7607, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(test_loader))\n",
    "\n",
    "x_out = classifer(x)\n",
    "print(x_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = out1[0].repeat(128, 1, 1, 1)\n",
    "\n",
    "# find closest in `out`\n",
    "distances = []\n",
    "for i in range(128):\n",
    "    distances.append(F.mse_loss(out1[i], out).mean())\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = classifer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "\n",
    "fig, ax = plt.subplots(8, 8, figsize=(8, 8))\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        ax[i, j].imshow(x[i * 8 + j].squeeze().numpy(), cmap=\"gray\")\n",
    "        ax[i, j].axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, width: int, depth: int=1):\n",
    "        def block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                # nn.BatchNorm2d(in_channels),\n",
    "                DepthwiseSeparableConv2d(in_channels, out_channels, 3, padding=1),\n",
    "                nn.GELU(),\n",
    "                # nn.BatchNorm2d(out_channels),\n",
    "                DepthwiseSeparableConv2d(out_channels, out_channels, 3, padding=1),\n",
    "                nn.GELU(),\n",
    "            )\n",
    "        \n",
    "        def stack(in_channels, out_channels, n_blocks = depth):\n",
    "            return nn.Sequential(\n",
    "                *[\n",
    "                    block(in_channels, out_channels)\n",
    "                    if i == 0\n",
    "                    else block(out_channels, out_channels)\n",
    "                    for i in range(n_blocks)\n",
    "                  ]\n",
    "                )\n",
    "\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            stack(1, width),\n",
    "            nn.MaxPool2d(2),\n",
    "            stack(width, width*2),\n",
    "            nn.MaxPool2d(2),\n",
    "            stack(width*2, width*4),\n",
    "            nn.MaxPool2d(2),\n",
    "            stack(width*4, width*8),\n",
    "            \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            stack(width*8, width*4),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            stack(width*4, width*2),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            stack(width*2, width),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            stack(width, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    #     self.encoder.apply(self.init_weights)\n",
    "    #     self.decoder.apply(self.init_weights)\n",
    "        \n",
    "    # def init_weights(self, m):\n",
    "    #     if type(m) == nn.Conv2d:\n",
    "    #         nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    #         m.bias.data.fill_(0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        return F.mse_loss(x, y)\n",
    "        \n",
    "model = AutoEncoder(width=32, depth=4).to(\"mps\")\n",
    "summary(model, (1, 1, 32, 32), device=\"mps\",depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)\n",
    "# ema = EMA(model, beta=0.999, update_after_step=100, update_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "test_loss = 0\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "    for img, _ in pbar:\n",
    "        img = img.to(\"mps\")\n",
    "        \n",
    "        output = model(img)\n",
    "        loss = model.loss(output, img)\n",
    "        optimizer.zero_grad()    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ema.update()\n",
    "        pbar.set_postfix({\"loss\": loss.item(), \"test_loss\": test_loss})\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for img, _ in tqdm(test_loader, desc=\"Testing\", leave=True):\n",
    "            img = img.to(\"mps\")\n",
    "            output = model(img)\n",
    "            loss = model.loss(output, img)\n",
    "            test_loss += loss\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_loss = test_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def plot_reconstructions(model):\n",
    "    model.eval()\n",
    "    img, _ = next(iter(test_loader))\n",
    "    img = img.to(\"mps\")\n",
    "    output = model(img)\n",
    "    display(\n",
    "        torchvision.transforms.ToPILImage()(\n",
    "            torchvision.utils.make_grid(\n",
    "                output\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "plot_reconstructions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "@torch.no_grad()\n",
    "def codebook_usage(model, loader):\n",
    "    model.eval()\n",
    "    counter = Counter()\n",
    "    for img, _ in tqdm(loader, desc=\"Calculating codebook usage\"):\n",
    "        img = img.to(\"mps\")\n",
    "        output = model(img)\n",
    "        idxs = output[4]\n",
    "        counter.update(idxs.cpu().numpy().flatten())\n",
    "    return counter\n",
    "\n",
    "# plot codebook usage\n",
    "usasge = codebook_usage(model, test_loader)\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.imshow(\n",
    "    torch.tensor([usasge[i] for i in range(512)]).reshape(16, 32).numpy(),\n",
    "    cmap=\"hot\",\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(usasge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
