{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# run = wandb.init()\n",
    "# artifact = run.use_artifact('karanravindra/mnist-autoencoder/model-o31mbhqq:v0', type='model')\n",
    "# artifact_dir = artifact.download()\n",
    "# run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchinfo import summary\n",
    "from nn_zoo.models.components import DepthwiseSeparableConv2d, VectorQuantizer\n",
    "from torchmetrics.functional.image import structural_similarity_index_measure as ssim_func\n",
    "import lpips\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, num_layers: int):\n",
    "        super(Block, self).__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                self._block(in_channels, out_channels)\n",
    "                if i == 0\n",
    "                else self._block(out_channels, out_channels)\n",
    "                for i in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels: int, out_channels: int):\n",
    "        return nn.Sequential(\n",
    "            nn.GroupNorm(1, in_channels),\n",
    "            nn.GELU(),\n",
    "            DepthwiseSeparableConv2d(in_channels, out_channels, 3),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers[0](x)\n",
    "        for i, layer in enumerate(self.layers[1:]):\n",
    "            x = layer(x) + x\n",
    "        return x\n",
    "\n",
    "\n",
    "class DownBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels: int, out_channels: int, depth: int):\n",
    "        super(DownBlock, self).__init__(\n",
    "            Block(in_channels * 4, out_channels, depth),\n",
    "            # nn.MaxPool2d(2)\n",
    "            nn.PixelUnshuffle(2),\n",
    "        )\n",
    "\n",
    "\n",
    "class UpBlock(nn.Sequential):\n",
    "    def __init__(self, in_channels: int, out_channels: int, depth: int):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.PixelShuffle(2),\n",
    "            # nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
    "            Block(in_channels, out_channels * 4, depth),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, width: int, depth: int):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            Block(1, width * 4, depth),\n",
    "            DownBlock(width, width, depth),\n",
    "            DownBlock(width, width, depth),\n",
    "            DownBlock(width, width, depth),\n",
    "            DepthwiseSeparableConv2d(width * 4, width * 2, 1, padding=0),\n",
    "        )\n",
    "        self.proj_in = nn.Identity()\n",
    "        self.vq = nn.Identity()\n",
    "        # VectorQuantizer(width, 8, use_ema=True, decay=0.99, epsilon=1e-5)\n",
    "        self.proj_out = nn.Identity()  # nn.Conv2d(width, width, 1)\n",
    "        self.decoder = nn.Sequential(\n",
    "            DepthwiseSeparableConv2d(width * 2, width * 4, 1, padding=0),\n",
    "            UpBlock(width, width, depth),\n",
    "            UpBlock(width, width, depth),\n",
    "            UpBlock(width, width, depth),\n",
    "            Block(width * 4, 1, depth),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.register_module(\n",
    "            \"lpips\", lpips.LPIPS(net=\"squeeze\", verbose=False, lpips=False)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.proj_in(x)\n",
    "        return self.vq(x)  # quant_x, dict_loss, commit_loss, indices = self.vq(x)\n",
    "\n",
    "    def decode(self, x):\n",
    "        x = self.proj_out(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encode(x)\n",
    "        x = self.decode(x)\n",
    "        return x\n",
    "\n",
    "    # @classmethod\n",
    "    def loss(self, x, y):\n",
    "        mse = F.mse_loss(x, y)\n",
    "        bce = F.binary_cross_entropy((x + 1) / 2, (y + 1) / 2)\n",
    "        psnr = 10 * (1 / mse).log10()\n",
    "        ssim = ssim_func(x, y)\n",
    "        lpips = self.lpips(x.repeat(1, 3, 1, 1), y.repeat(1, 3, 1, 1)).mean()\n",
    "\n",
    "        return {\n",
    "            \"loss\": bce + lpips,\n",
    "            \"bce\": bce,\n",
    "            \"mse\": mse,\n",
    "            \"ssim\": ssim,\n",
    "            \"psnr\": psnr,\n",
    "            \"lpips\": lpips,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(4, 2)\n",
    "state_dict = torch.load(\"artifacts/model-o31mbhqq:v0/model.ckpt\", map_location=torch.device('mps'))['state_dict']\n",
    "state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from nn_zoo.datamodules import MNISTDataModule\n",
    "\n",
    "dm = MNISTDataModule(\n",
    "        data_dir=\"../../../data\",\n",
    "        dataset_params={\n",
    "            \"download\": True,\n",
    "            \"transform\": torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.Resize((32, 32)),\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Lambda(lambda x: x * 2 - 1),\n",
    "                ]\n",
    "            )\n",
    "        },\n",
    "        loader_params={\n",
    "            \"batch_size\": 128,\n",
    "        },\n",
    "    )\n",
    "\n",
    "dm.setup()\n",
    "\n",
    "train_loader = dm.train_dataloader()\n",
    "val_loader = dm.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomMask:\n",
    "    def __init__(self, patch_size, mask_prob=0.5, mask_value=-1):\n",
    "        self.patch_size = (patch_size, patch_size)\n",
    "        self.mask_prob = mask_prob\n",
    "        self.mask_value = mask_value\n",
    "        \n",
    "\n",
    "    def __call__(self, x):\n",
    "        start_pos = torch.randint(0+2, x.shape[-1]-2, (2,), device=x.device)\n",
    "        num_to_mask = int(self.mask_prob * self.patch_size[0] * self.patch_size[1])\n",
    "        mask = torch.ones_like(x)\n",
    "        mask[\n",
    "            :,\n",
    "            :,\n",
    "            start_pos[0] : start_pos[0] + self.patch_size[0],\n",
    "            start_pos[1] : start_pos[1] + self.patch_size[1],\n",
    "        ] = self.mask_value\n",
    "        \n",
    "\n",
    "        return x * mask\n",
    "\n",
    "        # x[\n",
    "        #     :,\n",
    "        #     :,\n",
    "            \n",
    "        #     start_pos[0] : start_pos[0] + self.patch_size[0],\n",
    "        #     start_pos[1] : start_pos[1] + self.patch_size[1],\n",
    "        # ] = self.mask_value\n",
    "\n",
    "        # return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x, y = next(iter(val_loader))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(torchvision.utils.make_grid((x + 1) / 2, nrow=8).permute(1, 2, 0).cpu().numpy())\n",
    "plt.axis('off')\n",
    "\n",
    "masker = RandomMask(0)\n",
    "x_masked = masker(x)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(torchvision.utils.make_grid((x_masked + 1) / 2, nrow=8).permute(1, 2, 0).cpu().numpy())\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, masker: int = 0):\n",
    "    model.eval()\n",
    "    metrics = []\n",
    "    masker = RandomMask(patch_size=masker)\n",
    "    for x, y in tqdm(loader, desc=\"Evaluating\"):\n",
    "        x = x.to(\"mps\")\n",
    "        x_masked = masker(x.clone())\n",
    "        y_hat = model(x_masked)\n",
    "        metrics.append(model.loss(y_hat, x))\n",
    "\n",
    "    return {k: sum(m[k] for m in metrics) / len(metrics) for k in metrics[0]}\n",
    "\n",
    "evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_pytorch import EMA\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "ema = EMA(model, beta=0.9999, update_after_step=100, update_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "for epoch in range(10):\n",
    "    masker = RandomMask(0)\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    for x, y in pbar:\n",
    "        x = x.to(\"mps\")\n",
    "        x_masked = masker(x.clone())\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x_masked)\n",
    "        loss = model.loss(y_hat, x)\n",
    "        loss['loss'].backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ema.update()\n",
    "        pbar.set_postfix_str(\"\".join([f\"{k}: {v.item():.2f} \" for k, v in loss.items()]))\n",
    "\n",
    "\n",
    "    metrics = evaluate(model, val_loader)\n",
    "    print(\"\".join([f\"{k}: {v.item():.4f} \" for k, v in metrics.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
