{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 30])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"brackets.txt\", \"r\") as f:\n",
    "    brackets = f.readlines()\n",
    "idxs = list(map(lambda line: list(map(lambda val: int(val), line.split())), brackets))\n",
    "idxs = torch.tensor(idxs, dtype=torch.long)\n",
    "idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_split = 0.8\n",
    "train_size = int(train_val_split * len(idxs))\n",
    "\n",
    "train_idxs = idxs[:train_size]\n",
    "val_idxs = idxs[train_size:]\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(train_idxs[:, :-1], train_idxs[:, 1:])\n",
    "val_dataset = torch.utils.data.TensorDataset(val_idxs[:, :-1], val_idxs[:, 1:])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SOS <{[[<{{}}>]]}> EOS____________________________'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_char = {\n",
    "    0: \"{\",\n",
    "    1: \"(\",\n",
    "    2: \"[\",\n",
    "    3: \"<\",\n",
    "    4: \"}\",\n",
    "    5: \")\",\n",
    "    6: \"]\",\n",
    "    7: \">\",\n",
    "    8: \"SOS \",\n",
    "    9: \" EOS\",\n",
    "    10: \"__\"\n",
    "}\n",
    "def decode_brackets(brackets):\n",
    "    brackets = brackets.tolist()\n",
    "    return \"\".join([idx_to_char[idx] for idx in brackets])\n",
    "\n",
    "decode_brackets(idxs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for inputs, targets in data_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        outputs, loss = model(inputs, targets)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "RNN                                      [1024, 31, 10]            --\n",
       "├─Embedding: 1-1                         [1024, 64]                640\n",
       "├─RNNCell: 1-2                           [1024, 64]                --\n",
       "│    └─Linear: 2-1                       [1024, 64]                4,160\n",
       "│    └─Linear: 2-2                       [1024, 64]                4,160\n",
       "├─Linear: 1-3                            [1024, 10]                640\n",
       "├─Embedding: 1-4                         [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-5                           [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-3                       [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-4                       [1024, 64]                (recursive)\n",
       "├─Linear: 1-6                            [1024, 10]                (recursive)\n",
       "├─Embedding: 1-7                         [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-8                           [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-5                       [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-6                       [1024, 64]                (recursive)\n",
       "├─Linear: 1-9                            [1024, 10]                (recursive)\n",
       "├─Embedding: 1-10                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-11                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-7                       [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-8                       [1024, 64]                (recursive)\n",
       "├─Linear: 1-12                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-13                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-14                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-9                       [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-10                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-15                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-16                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-17                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-11                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-12                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-18                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-19                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-20                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-13                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-14                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-21                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-22                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-23                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-15                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-16                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-24                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-25                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-26                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-17                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-18                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-27                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-28                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-29                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-19                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-20                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-30                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-31                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-32                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-21                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-22                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-33                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-34                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-35                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-23                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-24                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-36                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-37                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-38                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-25                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-26                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-39                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-40                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-41                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-27                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-28                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-42                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-43                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-44                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-29                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-30                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-45                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-46                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-47                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-31                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-32                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-48                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-49                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-50                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-33                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-34                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-51                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-52                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-53                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-35                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-36                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-54                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-55                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-56                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-37                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-38                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-57                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-58                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-59                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-39                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-40                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-60                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-61                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-62                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-41                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-42                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-63                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-64                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-65                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-43                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-44                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-66                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-67                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-68                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-45                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-46                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-69                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-70                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-71                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-47                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-48                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-72                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-73                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-74                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-49                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-50                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-75                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-76                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-77                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-51                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-52                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-78                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-79                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-80                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-53                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-54                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-81                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-82                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-83                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-55                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-56                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-84                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-85                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-86                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-57                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-58                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-87                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-88                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-89                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-59                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-60                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-90                           [1024, 10]                (recursive)\n",
       "├─Embedding: 1-91                        [1024, 64]                (recursive)\n",
       "├─RNNCell: 1-92                          [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-61                      [1024, 64]                (recursive)\n",
       "│    └─Linear: 2-62                      [1024, 64]                (recursive)\n",
       "├─Linear: 1-93                           [1024, 10]                (recursive)\n",
       "==========================================================================================\n",
       "Total params: 9,600\n",
       "Trainable params: 9,600\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 304.74\n",
       "==========================================================================================\n",
       "Input size (MB): 0.25\n",
       "Forward/backward pass size (MB): 51.30\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 51.59\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNNCell, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W = nn.Linear(hidden_size, hidden_size)\n",
    "        self.U = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        h = torch.tanh(self.W(x) + self.U(h))\n",
    "\n",
    "        return h, h\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = RNNCell(hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, input_size, bias=False)\n",
    "\n",
    "        self.output.weight = self.embedding.weight\n",
    "\n",
    "    def forward(self, x, targets=None, h=None):\n",
    "        if h is None:\n",
    "            h = torch.zeros(x.size(0), self.hidden_size, device=x.device)\n",
    "        outputs = []\n",
    "        loss = torch.tensor(0.0, device=x.device)\n",
    "        for i in range(x.size(1)):\n",
    "            x_t = self.embedding(x[:, i])\n",
    "            h, _ = self.rnn(x_t, h)\n",
    "            y_pred = self.output(h)\n",
    "            outputs.append(y_pred)\n",
    "            if targets is not None:\n",
    "                loss += nn.functional.cross_entropy(y_pred, targets[:, i])\n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        \n",
    "        return (outputs) if targets is None else (outputs, loss / x.size(1))\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def generate(self, x=None, h=None, max_len=10, temperature=1.0):\n",
    "        if h is None:\n",
    "            h = torch.zeros(1, self.hidden_size, device=device)\n",
    "        if x is None:\n",
    "            x = torch.tensor([[8]], dtype=torch.long, device=device)\n",
    "        outputs = []\n",
    "        for i in range(max_len):\n",
    "            x_t = self.embedding(x)\n",
    "            h, _ = self.rnn(x_t, h)\n",
    "            y_pred = self.output(h) / temperature\n",
    "            y_pred = y_pred.argmax(dim=1)\n",
    "            outputs.append(y_pred)\n",
    "            x = y_pred\n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        return outputs\n",
    "\n",
    "model = RNN(10, 64).to(device)\n",
    "summary(model, (1024, 31), dtypes=[torch.long], device=device)\n",
    "# decode_brackets(model.generate().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 313/313 [00:09<00:00, 32.19it/s, loss=0.74, val_loss=inf] \n",
      "Epoch 1: 100%|██████████| 313/313 [00:09<00:00, 33.29it/s, loss=0.615, val_loss=0.741]\n",
      "Epoch 2:   3%|▎         | 10/313 [00:00<00:09, 31.62it/s, loss=0.593, val_loss=0.587]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 13\u001b[0m outputs, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/projects/playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, x, targets, h)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m     29\u001b[0m     x_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x[:, i])\n\u001b[0;32m---> 30\u001b[0m     h, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(h)\n\u001b[1;32m     32\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(y_pred)\n",
      "File \u001b[0;32m~/projects/playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/playground/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36mRNNCell.forward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, h):\n\u001b[0;32m----> 9\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtanh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mU\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m h, h\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if \"val_loss\" in locals():\n",
    "    pass\n",
    "else:\n",
    "    val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    for inputs, targets in pbar:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        outputs, loss = model(inputs, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.set_postfix(loss=loss.item(), val_loss=val_loss)\n",
    "\n",
    "    val_loss = evaluate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{{'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_brackets(model.generate(\n",
    "    x=torch.tensor([[8]], dtype=torch.long, device=device),\n",
    "    h=torch.randn(1, 64, device=device),\n",
    ").flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[8, 1, 2, 3, 4, 5, 6, 7]], dtype=torch.long, device=device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
