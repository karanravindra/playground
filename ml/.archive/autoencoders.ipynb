{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_zoo import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import tqdm as tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = CIFARDataModule(\n",
    "    CIFARDataModuleConfig(\n",
    "        \"data\",\n",
    "        batch_size=128,\n",
    "        num_workers=4,\n",
    "        persistent_workers=True,\n",
    "        pin_memory=True,\n",
    "    )\n",
    ")\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "train_loader = dm.train_dataloader()\n",
    "val_loader = dm.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for x, _ in val_loader:\n",
    "            x = x.to(device)\n",
    "            _, loss = model(x, calc_loss=True)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, latent_dim=16):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Conv2d(1, 32, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, latent_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128 * 4 * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (128, 4, 4)),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, calc_loss) -> tuple[torch.Tensor, torch.Tensor | None]:\n",
    "        if not calc_loss:\n",
    "            z = self.encoder(x)\n",
    "            x_hat = self.decoder(z)\n",
    "            return x_hat, None\n",
    "\n",
    "        else:\n",
    "            z = self.encoder(x)\n",
    "            x_hat = self.decoder(z)\n",
    "\n",
    "            loss = F.mse_loss(x_hat, x)\n",
    "            return x_hat, loss\n",
    "\n",
    "\n",
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_loss = 0\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    val_loss = evaluate(model, val_loader)\n",
    "    pbar = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "\n",
    "    for x, _ in pbar:\n",
    "        x = x.to(device)\n",
    "        x_hat, loss = model(x, calc_loss=True)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        roll_loss = 0.9 * roll_loss + 0.1 * loss.item()\n",
    "\n",
    "        pbar.set_postfix_str(\n",
    "            f\"Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, Overfit: {loss.item() / val_loss:.4f}, Roll Loss: {roll_loss:.4f}, LR: {optimizer.param_groups[0]['lr']:.4f}\"\n",
    "        )\n",
    "\n",
    "    scheduler.step(roll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    values = []\n",
    "    classes = []\n",
    "    for x, y in val_loader:\n",
    "        x = x.to(device)\n",
    "        z = model.encoder(x)\n",
    "\n",
    "        values.append(z.cpu().numpy())\n",
    "        classes.append(y.cpu().numpy().flatten())\n",
    "\n",
    "    values = np.concatenate(values, axis=0)\n",
    "    classes = np.concatenate(classes, axis=0)\n",
    "\n",
    "    # Perform PCA for 3 highest components\n",
    "    pca = PCA(n_components=2)\n",
    "    values = pca.fit_transform(values)\n",
    "\n",
    "    fig = px.scatter(\n",
    "        x=values[:, 0],\n",
    "        y=values[:, 1],\n",
    "        color=classes,\n",
    "        labels={\"values\": values},\n",
    "        title=\"Latent Space\",\n",
    "        category_orders={\"color\": np.unique(classes)},\n",
    "        height=800,\n",
    "        \n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x, y = next(iter(val_loader))\n",
    "\n",
    "x = x.to(device)\n",
    "x_hat = model(x, calc_loss=False)[0].detach()\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8))\n",
    "for i in range(5):\n",
    "    axs[0, i].imshow(x[i].cpu().numpy().squeeze(), cmap=\"gray\")\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(x_hat[i].cpu().numpy().squeeze(), cmap=\"gray\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Reconstructed Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, latent_dim=4):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Dropout(0.5), # Dropout layer\n",
    "            nn.Conv2d(1, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 4 * 4, latent_dim),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128 * 4 * 4),\n",
    "            nn.Unflatten(1, (128, 4, 4)),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x, calc_loss) -> tuple[torch.Tensor, torch.Tensor | None]:\n",
    "        if not calc_loss:\n",
    "            z = self.encoder(x)\n",
    "            x_hat = self.decoder(z)\n",
    "            return x_hat, None\n",
    "\n",
    "        else:\n",
    "            z = self.encoder(x)\n",
    "            x_hat = self.decoder(z)\n",
    "\n",
    "            loss = F.mse_loss(x_hat, x)\n",
    "            return x_hat, loss\n",
    "\n",
    "\n",
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    val_loss = evaluate(model, val_loader)\n",
    "    pbar = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    for x, _ in pbar:\n",
    "        x = x.to(device)\n",
    "        x_hat, loss = model(x, calc_loss=True)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.set_postfix_str(\n",
    "            f\"Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, Overfit: {loss.item() / val_loss:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    values = []\n",
    "    classes = []\n",
    "    for x, y in val_loader:\n",
    "        x = x.to(device)\n",
    "        z = model.encoder(x)\n",
    "\n",
    "        values.append(z.cpu().numpy())\n",
    "        classes.append(y.cpu().numpy().flatten())\n",
    "\n",
    "    values = np.concatenate(values, axis=0)\n",
    "    classes = np.concatenate(classes, axis=0)\n",
    "\n",
    "    # Perform PCA for 3 highest components\n",
    "    pca = PCA(n_components=2)\n",
    "    values = pca.fit_transform(values)\n",
    "\n",
    "    fig = px.scatter(\n",
    "        x=values[:, 0],\n",
    "        y=values[:, 1],\n",
    "        color=classes,\n",
    "        labels={\"values\": values},\n",
    "        title=\"Latent Space\",\n",
    "        category_orders={\"color\": np.unique(classes)},\n",
    "        height=800,\n",
    "        \n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x, y = next(iter(val_loader))\n",
    "\n",
    "x = x.to(device)\n",
    "x_hat = model(x, calc_loss=False)[0].detach()\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8))\n",
    "for i in range(5):\n",
    "    axs[0, i].imshow(x[i].cpu().numpy().squeeze(), cmap=\"gray\")\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(x_hat[i].cpu().numpy().squeeze(), cmap=\"gray\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Reconstructed Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        self.logvar = nn.Linear(128 * 4 * 4, latent_dim) # Log variance\n",
    "        self.mu = nn.Linear(128 * 4 * 4, latent_dim) # Mean\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128 * 4 * 4),\n",
    "            nn.Unflatten(1, (128, 4, 4)),\n",
    "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x, calc_loss) -> tuple[torch.Tensor, torch.Tensor | None]:\n",
    "        if calc_loss:\n",
    "            z = self.encoder(x)\n",
    "            mean = self.mu(z)\n",
    "            logvar = self.logvar(z)\n",
    "            z = self.reparameterize(mean, logvar)\n",
    "\n",
    "            x_hat = self.decoder(z)\n",
    "\n",
    "            loss = F.mse_loss(x_hat, x) + (-0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp()))\n",
    "            return x_hat, loss\n",
    "        \n",
    "        else:\n",
    "            z = self.encoder(x)\n",
    "            mean = self.mu(z)\n",
    "            logvar = self.logvar(z)\n",
    "            z = self.reparameterize(mean, logvar)\n",
    "            x_hat = self.decoder(z)\n",
    "            return x_hat, None\n",
    "        \n",
    "    def reparameterize(self, mean, logvar): # Reparameterization trick\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std, device=device)\n",
    "        return mean + eps * std\n",
    "    \n",
    "\n",
    "\n",
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    val_loss = evaluate(model, val_loader)\n",
    "    pbar = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    for x, _ in pbar:\n",
    "        x = x.to(device)\n",
    "        x_hat, loss = model(x, calc_loss=True)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.set_postfix_str(\n",
    "            f\"Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, Overfit: {loss.item() / val_loss:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    values = []\n",
    "    classes = []\n",
    "    for x, y in val_loader:\n",
    "        x = x.to(device)\n",
    "        z = model.encoder(x)\n",
    "\n",
    "        values.append(z.cpu().numpy())\n",
    "        classes.append(y.cpu().numpy().flatten())\n",
    "\n",
    "    values = np.concatenate(values, axis=0)\n",
    "    classes = np.concatenate(classes, axis=0)\n",
    "\n",
    "    # Perform PCA for 3 highest components\n",
    "    pca = PCA(n_components=2)\n",
    "    values = pca.fit_transform(values)\n",
    "\n",
    "    fig = px.scatter(\n",
    "        x=values[:, 0],\n",
    "        y=values[:, 1],\n",
    "        color=classes,\n",
    "        labels={\"values\": values},\n",
    "        title=\"Latent Space\",\n",
    "        category_orders={\"color\": np.unique(classes)},\n",
    "        height=800,\n",
    "        \n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x, y = next(iter(val_loader))\n",
    "\n",
    "x = x.to(device)\n",
    "x_hat = model(x, calc_loss=False)[0].detach()\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8))\n",
    "for i in range(5):\n",
    "    axs[0, i].imshow(x[i].cpu().permute(1, 2, 0))\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(x_hat[i].cpu().permute(1, 2, 0))\n",
    "    axs[1, i].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Reconstructed Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, latent_dim=4):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3,  stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1),\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x, calc_loss) -> tuple[torch.Tensor, torch.Tensor | None]:\n",
    "        if not calc_loss:\n",
    "            z = self.encoder(x)\n",
    "            x_hat = self.decoder(z)\n",
    "            return x_hat, None\n",
    "\n",
    "        else:\n",
    "            z = self.encoder(x)\n",
    "            x_hat = self.decoder(z)\n",
    "\n",
    "            loss = F.mse_loss(x_hat, x) + 1e-3 * F.l1_loss(z, torch.zeros_like(z)) # L1 regularization\n",
    "            return x_hat, loss\n",
    "\n",
    "\n",
    "model = Model().to(device)\n",
    "model(torch.randn(1, 3, 32, 32, device=device), calc_loss=False)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    val_loss = evaluate(model, val_loader)\n",
    "    pbar = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    for x, _ in pbar:\n",
    "        x = x.to(device)\n",
    "        x_hat, loss = model(x, calc_loss=True)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.set_postfix_str(\n",
    "            f\"Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}, Overfit: {loss.item() / val_loss:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    values = []\n",
    "    classes = []\n",
    "    for x, y in val_loader:\n",
    "        x = x.to(device)\n",
    "        z = model.encoder(x)\n",
    "\n",
    "        values.append(z.cpu().numpy())\n",
    "        classes.append(y.cpu().numpy().flatten())\n",
    "\n",
    "    values = np.concatenate(values, axis=0)\n",
    "    classes = np.concatenate(classes, axis=0)\n",
    "\n",
    "    # Perform PCA for 3 highest components\n",
    "    pca = PCA(n_components=2)\n",
    "    values = pca.fit_transform(values)\n",
    "\n",
    "    fig = px.scatter(\n",
    "        x=values[:, 0],\n",
    "        y=values[:, 1],\n",
    "        color=classes,\n",
    "        labels={\"values\": values},\n",
    "        title=\"Latent Space\",\n",
    "        category_orders={\"color\": np.unique(classes)},\n",
    "        height=800,\n",
    "        \n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x, y = next(iter(val_loader))\n",
    "\n",
    "x = x.to(device)\n",
    "x_hat = model(x, calc_loss=False)[0].detach()\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20, 8))\n",
    "for i in range(5):\n",
    "    axs[0, i].imshow(x[i].cpu().numpy().squeeze(), cmap=\"gray\")\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(x_hat[i].cpu().numpy().squeeze(), cmap=\"gray\")\n",
    "    axs[1, i].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Reconstructed Images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print encoded images\n",
    "model.eval()\n",
    "x, y = next(iter(val_loader))\n",
    "print(model.encoder(x.to(device))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
