{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Operator:\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "\n",
    "    def __call__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, grad):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "class Add(Operator):\n",
    "    def __call__(self):\n",
    "        return self.args[0] + self.args[1]\n",
    "\n",
    "    def backward(self, grad):\n",
    "        return grad, grad\n",
    "    \n",
    "class Mul(Operator):\n",
    "    def __call__(self):\n",
    "        return self.args[0] * self.args[1]\n",
    "\n",
    "    def backward(self, grad):\n",
    "        return grad * self.args[1], grad * self.args[0]\n",
    "    \n",
    "class Matmul(Operator):\n",
    "    def __call__(self):\n",
    "        return np.dot(self.args[0], self.args[1])\n",
    "\n",
    "    def backward(self, grad):\n",
    "        return np.dot(grad, self.args[1].T), np.dot(self.args[0].T, grad)\n",
    "    \n",
    "class Sum(Operator):\n",
    "    def __call__(self):\n",
    "        return np.sum(self.args[0])\n",
    "\n",
    "    def backward(self, grad):\n",
    "        return grad * np.ones_like(self.args[0])\n",
    "\n",
    "class Tensor:\n",
    "    def __init__(self, data, requires_grad=False):\n",
    "        self.data = np.array(data)\n",
    "        self.requires_grad = requires_grad\n",
    "        self.grad = np.zeros_like(self.data) if requires_grad else None\n",
    "        self._grad_fn = None\n",
    "\n",
    "    def __add__(self, other):\n",
    "        other_data = other.data if isinstance(other, Tensor) else other\n",
    "        result = Tensor(self.data + other_data, requires_grad=self.requires_grad or (isinstance(other, Tensor) and other.requires_grad))\n",
    "        if self.requires_grad:\n",
    "            result._grad_fn = ('add', self, other)\n",
    "        return result\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other_data = other.data if isinstance(other, Tensor) else other\n",
    "        result = Tensor(self.data * other_data, requires_grad=self.requires_grad or (isinstance(other, Tensor) and other.requires_grad))\n",
    "        if self.requires_grad:\n",
    "            result._grad_fn = ('mul', self, other)\n",
    "        return result\n",
    "\n",
    "    def matmul(self, other):\n",
    "        assert isinstance(other, Tensor), \"matmul requires another tensor.\"\n",
    "        result = Tensor(np.dot(self.data, other.data), requires_grad=self.requires_grad or other.requires_grad)\n",
    "        if self.requires_grad:\n",
    "            result._grad_fn = ('matmul', self, other)\n",
    "        return result\n",
    "    \n",
    "    def sum(self):\n",
    "        result = Tensor(np.sum(self.data), requires_grad=self.requires_grad)\n",
    "        if self.requires_grad:\n",
    "            result._grad_fn = ('sum', self)\n",
    "        return result\n",
    "\n",
    "    def backward(self, grad=None):\n",
    "        if self.grad is None:\n",
    "            raise RuntimeError(\"Gradients are not being tracked for this tensor.\")\n",
    "        if grad is None:\n",
    "            grad = np.ones_like(self.data)\n",
    "        self.grad += grad\n",
    "        self._backward()\n",
    "\n",
    "    def _backward(self):\n",
    "        if self._grad_fn is None:\n",
    "            return\n",
    "\n",
    "        op, left, right = self._grad_fn\n",
    "        if op == 'add':\n",
    "            if left.requires_grad:\n",
    "                left.grad += self.grad\n",
    "            if isinstance(right, Tensor) and right.requires_grad:\n",
    "                right.grad += self.grad\n",
    "            left._backward()\n",
    "            if isinstance(right, Tensor):\n",
    "                right._backward()\n",
    "        elif op == 'mul':\n",
    "            if left.requires_grad:\n",
    "                left.grad += self.grad * (right.data if isinstance(right, Tensor) else right)\n",
    "            if isinstance(right, Tensor) and right.requires_grad:\n",
    "                right.grad += self.grad * left.data\n",
    "            left._backward()\n",
    "            if isinstance(right, Tensor):\n",
    "                right._backward()\n",
    "        elif op == 'matmul':\n",
    "            if left.requires_grad:\n",
    "                left.grad += np.dot(self.grad, right.data.T)\n",
    "            if right.requires_grad:\n",
    "                right.grad += np.dot(left.data.T, self.grad)\n",
    "            left._backward()\n",
    "            right._backward()\n",
    "        elif op == 'sum':\n",
    "            if left.requires_grad:\n",
    "                left.grad += self.grad\n",
    "            left._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar operations:\n",
      "Value of a: 2.0\n",
      "Gradient of a: 4.0\n",
      "Value of b: 3.0\n",
      "Gradient of b: 2.0\n",
      "10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m z \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(z\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMatrix operations:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue of x:\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mdata)\n",
      "Cell \u001b[0;32mIn[11], line 43\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, grad)\u001b[0m\n\u001b[1;32m     41\u001b[0m     grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones_like(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grad\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 49\u001b[0m, in \u001b[0;36mTensor._backward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m op, left, right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grad_fn\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m left\u001b[38;5;241m.\u001b[39mrequires_grad:\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "# Create scalar tensors with gradient tracking\n",
    "a = Tensor(2.0, requires_grad=True)\n",
    "b = Tensor(3.0, requires_grad=True)\n",
    "\n",
    "# Scalar operations\n",
    "c = a * b + a\n",
    "c.backward()\n",
    "\n",
    "print(\"Scalar operations:\")\n",
    "print(\"Value of a:\", a.data)\n",
    "print(\"Gradient of a:\", a.grad)\n",
    "print(\"Value of b:\", b.data)\n",
    "print(\"Gradient of b:\", b.grad)\n",
    "\n",
    "# Create matrix tensors with gradient tracking\n",
    "x = Tensor([[1, 2], [3, 4]], requires_grad=True)\n",
    "y = Tensor([[5, 6], [7, 8]], requires_grad=True)\n",
    "\n",
    "# Matrix operations\n",
    "z = x.matmul(y) + x\n",
    "z = x.sum()\n",
    "print(z.data)\n",
    "z.backward()\n",
    "\n",
    "print(\"\\nMatrix operations:\")\n",
    "print(\"Value of x:\", x.data)\n",
    "print(\"Gradient of x:\", x.grad)\n",
    "print(\"Value of y:\", y.data)\n",
    "print(\"Gradient of y:\", y.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
