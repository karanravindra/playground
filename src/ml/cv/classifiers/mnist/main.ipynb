{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from ema_pytorch import EMA\n",
    "from torchinfo import summary\n",
    "from ml_zoo.datamodules import MNISTDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MNISTDataModule(\n",
    "    data_dir=\"data\",\n",
    "    dataset_params={\n",
    "        \"download\": True,\n",
    "        \"transform\": torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize((32, 32)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ]\n",
    "        ),\n",
    "    },\n",
    "    loader_params={\n",
    "        \"batch_size\": 128,\n",
    "        \"num_workers\": 2,\n",
    "    },\n",
    ")\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "trian_loader = dm.train_dataloader()\n",
    "test_loader = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Classifer                                [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 16, 2, 2]             --\n",
       "│    └─BatchNorm2d: 2-1                  [1, 1, 32, 32]            2\n",
       "│    └─Conv2d: 2-2                       [1, 8, 32, 32]            80\n",
       "│    └─GELU: 2-3                         [1, 8, 32, 32]            --\n",
       "│    └─MaxPool2d: 2-4                    [1, 8, 16, 16]            --\n",
       "│    └─BatchNorm2d: 2-5                  [1, 8, 16, 16]            16\n",
       "│    └─Conv2d: 2-6                       [1, 16, 16, 16]           1,168\n",
       "│    └─GELU: 2-7                         [1, 16, 16, 16]           --\n",
       "│    └─MaxPool2d: 2-8                    [1, 16, 8, 8]             --\n",
       "│    └─BatchNorm2d: 2-9                  [1, 16, 8, 8]             32\n",
       "│    └─Conv2d: 2-10                      [1, 16, 8, 8]             2,320\n",
       "│    └─GELU: 2-11                        [1, 16, 8, 8]             --\n",
       "│    └─MaxPool2d: 2-12                   [1, 16, 4, 4]             --\n",
       "│    └─BatchNorm2d: 2-13                 [1, 16, 4, 4]             32\n",
       "│    └─Conv2d: 2-14                      [1, 16, 4, 4]             2,320\n",
       "│    └─GELU: 2-15                        [1, 16, 4, 4]             --\n",
       "│    └─MaxPool2d: 2-16                   [1, 16, 2, 2]             --\n",
       "├─Sequential: 1-2                        [1, 10]                   --\n",
       "│    └─GELU: 2-17                        [1, 64]                   --\n",
       "│    └─BatchNorm1d: 2-18                 [1, 64]                   128\n",
       "│    └─Linear: 2-19                      [1, 10]                   650\n",
       "==========================================================================================\n",
       "Total params: 6,748\n",
       "Trainable params: 6,748\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.57\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.14\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 0.18\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Classifer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifer, self).__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Conv2d(1, 8, 3, 1, 1),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(8, 16, 3, 1, 1),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 16, 3, 1, 1),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 16, 3, 1, 1),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(16 * 2 * 2),\n",
    "            nn.Linear(16 * 2 * 2, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x).view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Classifer().to(\"mps\")\n",
    "summary(\n",
    "    model,\n",
    "    input_data=torch.randn(1, 1, 32, 32, device=\"mps\", requires_grad=False),\n",
    "    depth=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema = EMA(model, beta=0.9999, update_after_step=100, update_every=10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=4e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 469/469 [00:08<00:00, 56.53it/s, loss: 0.1224, test_loss: 0.0000, test_acc: 0.0000]\n",
      "Testing: 100%|██████████| 79/79 [00:01<00:00, 45.10it/s]\n",
      "Epoch 2: 100%|██████████| 469/469 [00:06<00:00, 71.00it/s, loss: 0.0630, test_loss: 0.1456, test_acc: 0.9712]\n",
      "Testing: 100%|██████████| 79/79 [00:01<00:00, 47.03it/s]\n",
      "Epoch 3: 100%|██████████| 469/469 [00:06<00:00, 71.45it/s, loss: 0.0466, test_loss: 0.0758, test_acc: 0.9823]\n",
      "Testing: 100%|██████████| 79/79 [00:01<00:00, 46.98it/s]\n",
      "Epoch 4: 100%|██████████| 469/469 [00:06<00:00, 69.54it/s, loss: 0.0406, test_loss: 0.0573, test_acc: 0.9839]\n",
      "Testing: 100%|██████████| 79/79 [00:01<00:00, 46.80it/s]\n",
      "Epoch 5: 100%|██████████| 469/469 [00:06<00:00, 73.09it/s, loss: 0.0433, test_loss: 0.0474, test_acc: 0.9857]\n",
      "Testing: 100%|██████████| 79/79 [00:01<00:00, 45.71it/s]\n",
      "Epoch 6: 100%|██████████| 469/469 [00:06<00:00, 72.39it/s, loss: 0.0812, test_loss: 0.0504, test_acc: 0.9845]\n",
      "Testing: 100%|██████████| 79/79 [00:01<00:00, 46.11it/s]\n",
      "Epoch 7: 100%|██████████| 469/469 [00:06<00:00, 71.58it/s, loss: 0.0590, test_loss: 0.0809, test_acc: 0.9742]\n",
      "Testing: 100%|██████████| 79/79 [00:01<00:00, 39.80it/s]\n",
      "Epoch 8: 100%|██████████| 469/469 [00:07<00:00, 64.60it/s, loss: 0.0492, test_loss: 0.0566, test_acc: 0.9825]\n",
      "Testing: 100%|██████████| 79/79 [00:01<00:00, 41.74it/s]\n",
      "Epoch 9:  10%|▉         | 46/469 [00:02<00:20, 20.55it/s, loss: 0.0430, test_loss: 0.0484, test_acc: 0.9855]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 16\u001b[0m roll_loss \u001b[38;5;241m=\u001b[39m roll_loss \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.9\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     18\u001b[0m ema\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     19\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroll_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, test_acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "roll_loss = 0\n",
    "test_loss = 0\n",
    "test_acc = 0\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    pbar = tqdm(trian_loader, desc=f\"Epoch {epoch+1}\")\n",
    "    for img, label in pbar:\n",
    "        img, label = img.to(\"mps\"), label.to(\"mps\")\n",
    "        optimizer.zero_grad()\n",
    "        output = model(img)\n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        roll_loss = roll_loss * 0.9 + loss.item() * 0.1\n",
    "\n",
    "        ema.update()\n",
    "        pbar.set_postfix_str(f\"loss: {roll_loss:.4f}, test_loss: {test_loss:.4f}, test_acc: {test_acc:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(test_loader, desc=\"Testing\", leave=True):\n",
    "            img, label = img.to(\"mps\"), label.to(\"mps\")\n",
    "            output = model(img)\n",
    "            test_loss += criterion(output, label)\n",
    "            test_acc += (output.argmax(1) == label).float().mean()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_loss = test_loss.item()\n",
    "    test_acc /= len(test_loader)\n",
    "    test_acc = test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
