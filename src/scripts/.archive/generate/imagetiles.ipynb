{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiles: 128 x 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k1/y4w577ts6qb9hpql_4lr_km40000gn/T/ipykernel_57803/1089791483.py:37: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n",
      "  for i in tqdm.tnrange(num_tiles_x):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33deb06ee12e4603aa45a6daa1f3bc1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "device = \"mps\"\n",
    "\n",
    "def load_images(image_dir, tile_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(tile_size),  # Resize to uniform size\n",
    "        transforms.ToTensor()           # Convert to tensor\n",
    "    ])\n",
    "    dataset = ImageFolder(root=image_dir, transform=transform)\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=len(dataset), shuffle=False)\n",
    "    all_images, _ = next(iter(loader))\n",
    "    return all_images.to(device)\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    return transforms.ToPILImage()(tensor)\n",
    "\n",
    "def assemble_mosaic(target_image_path, small_images, tile_size=(64, 64), mosaic_size=(1024, 1024)):\n",
    "    target_image = Image.open(target_image_path)\n",
    "    target_image = target_image.resize(mosaic_size)\n",
    "    target_tensor = transforms.ToTensor()(target_image).to(device)\n",
    "\n",
    "    # Calculate number of tiles\n",
    "    num_tiles_x = mosaic_size[0] // tile_size[0]\n",
    "    num_tiles_y = mosaic_size[1] // tile_size[1]\n",
    "\n",
    "    print(f'Number of tiles: {num_tiles_x} x {num_tiles_y}')\n",
    "\n",
    "    # Initialize mosaic tensor\n",
    "    mosaic = torch.zeros(3, mosaic_size[1], mosaic_size[0], device=device)\n",
    "\n",
    "    for i in tqdm.tnrange(num_tiles_x):\n",
    "        for j in range(num_tiles_y):\n",
    "            x = i * tile_size[0]\n",
    "            y = j * tile_size[1]\n",
    "            region = target_tensor[:, y:y+tile_size[1], x:x+tile_size[0]]\n",
    "            avg_color = region.reshape(3, -1).mean(dim=1)\n",
    "\n",
    "            # Find the closest tile\n",
    "            distances = torch.norm(small_images - avg_color[:, None, None], dim=1, p=2).mean([1, 2])\n",
    "            closest_img_idx = torch.argmin(distances)\n",
    "            closest_img = small_images[closest_img_idx]\n",
    "\n",
    "            # Place tile into mosaic\n",
    "            mosaic[:, y:y+tile_size[1], x:x+tile_size[0]] = closest_img\n",
    "\n",
    "    return tensor_to_image(mosaic)\n",
    "\n",
    "# Usage\n",
    "tile_size = (32, 32)\n",
    "mosaic_size = (4096, 4096)\n",
    "image_dir = 'data/celeba_hq/val'\n",
    "target_image_path = 'data/celeba_hq/val/male/000080.jpg'\n",
    "\n",
    "small_images = load_images(image_dir, tile_size)\n",
    "mosaic = assemble_mosaic(target_image_path, small_images, tile_size, mosaic_size)\n",
    "mosaic.save('mosaic.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
